{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capsule_layer(input_layer,kernel_size=6,strides=2,\n",
    "                  primary_block=32,primary_depth=8,\n",
    "                  secondary_block=10,secondary_depth=16):\n",
    "    \n",
    "    def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "        with tf.name_scope(name, default_name=\"squash\"):\n",
    "            squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                         keep_dims=True)\n",
    "            safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "            squash_factor = squared_norm / (1. + squared_norm)\n",
    "            unit_vector = s / safe_norm\n",
    "            return squash_factor * unit_vector\n",
    "        \n",
    "    def primary_capsule(input_layer,kernel_size,strides,primary_block,primary_depth):\n",
    "        conv2_params = {\n",
    "            \"filters\": primary_block * primary_depth, # 256 convolutional filters\n",
    "            \"kernel_size\": kernel_size, #Configureable //need to change to 5\n",
    "            \"strides\": strides,     #Configureable\n",
    "            \"padding\": \"valid\",\n",
    "            \"activation\": tf.nn.relu\n",
    "        }\n",
    "        \n",
    "        primary_layer_conv = tf.layers.conv2d(input_layer, **conv2_params)\n",
    "        primary_layer_raw = tf.reshape(primary_layer_conv, [-1, primary_block, primary_depth])\n",
    "        primary_layer = squash(primary_layer_raw)\n",
    "        return primary_layer\n",
    "    \n",
    "    def secondary_capsule(primary_layer,secondary_block,secondary_depth):\n",
    "        init_sigma = 0.01\n",
    "        batch_size = tf.shape(primary_layer)[0]\n",
    "        primary_n_caps = (int)(primary_layer.shape[1])\n",
    "        primary_depth  = (int)(primary_layer.shape[2])\n",
    "        \n",
    "        W_init = tf.random_normal(\n",
    "        shape=(1, primary_n_caps, secondary_block, secondary_depth, primary_depth),\n",
    "                  stddev=init_sigma, dtype=tf.float32)\n",
    "        W = tf.Variable(W_init)\n",
    "       \n",
    "        W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1])\n",
    "        \n",
    "        \n",
    "        caps1_output_expanded = tf.expand_dims(primary_layer, -1)\n",
    "        caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2)\n",
    "        caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, secondary_block, 1, 1])\n",
    "        \n",
    "        caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled)\n",
    "        \n",
    "           \n",
    "        #Routing by agreement\n",
    "        raw_weights = tf.zeros([batch_size, primary_n_caps, secondary_block, 1, 1],dtype=np.float32)\n",
    "        #Round 1\n",
    "        routing_weights = tf.nn.softmax(raw_weights, dim=2)\n",
    "       \n",
    "        weighted_predictions = tf.multiply(routing_weights, caps2_predicted)\n",
    "           \n",
    "        weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True)\n",
    "        caps2_output_round_1 = squash(weighted_sum, axis=-2)\n",
    "            #Round 2\n",
    "        caps2_output_round_1_tiled = tf.tile(caps2_output_round_1, [1, primary_n_caps, 1, 1, 1])\n",
    "        agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled, transpose_a=True)\n",
    "        raw_weights_round_2 = tf.add(raw_weights, agreement)\n",
    "            \n",
    "        routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,dim=2)\n",
    "        weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,caps2_predicted)\n",
    "        weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,axis=1, keep_dims=True)\n",
    "        caps2_output_round_2 = squash(weighted_sum_round_2,axis=-2)\n",
    "        return caps2_output_round_2\n",
    "    \n",
    "    primary_layer = primary_capsule(input_layer,kernel_size,strides,primary_block,primary_depth)\n",
    "    secondary_layer = secondary_capsule(primary_layer,secondary_block,secondary_depth)\n",
    "    return secondary_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt \n",
    "image_width= sqrt(mnist.train.images.shape[1])\n",
    "image_height=image_width\n",
    "image_channel=1\n",
    "n_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, image_width, image_width, image_channel], dtype=tf.float32, name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_raw = tf.layers.conv2d(X, filters=256, kernel_size=9, strides=1, padding=\"valid\", activation=tf.nn.relu)\n",
    "conv1_keep_prob = tf.placeholder(tf.float32)\n",
    "conv1 = tf.nn.dropout(conv1_raw, conv1_keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsule1 = capsule_layer(conv1,kernel_size=6,strides=2,\n",
    "                  primary_block=32,primary_depth=8,\n",
    "                  secondary_block=10,secondary_depth=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsule_output = capsule1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "y_proba = safe_norm(capsule_output, axis=-2)\n",
    "y_proba_argmax = tf.argmax(y_proba, axis=2)\n",
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5\n",
    "T = tf.one_hot(y, depth=n_classes, name=\"T\")\n",
    "caps2_output_norm = safe_norm(capsule_output, axis=-2, keep_dims=True)\n",
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm))\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, n_classes))\n",
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus))\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, n_classes))\n",
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error, name=\"L\")\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
